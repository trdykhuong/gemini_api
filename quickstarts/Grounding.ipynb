{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "# Access the API key stored as a secret in Colab\n",
        "GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')"
      ],
      "metadata": {
        "id": "jNS-XekMfYgJ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Use Google Search grounding"
      ],
      "metadata": {
        "id": "5bhGlIGdethN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the necessary libraries for using the Google Generative AI client.\n",
        "from google import genai\n",
        "from google.genai import types\n",
        "\n",
        "# Initialize the client with the API key retrieved from Colab secrets.\n",
        "client = genai.Client(api_key=GOOGLE_API_KEY)\n",
        "\n",
        "# Define the model ID to be used for generating content.\n",
        "MODEL_ID = \"gemini-2.5-flash\""
      ],
      "metadata": {
        "id": "ZzXZpFJHeuhl"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import HTML, Markdown\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents='Trận đấu đội tuyển Anh với đội tuyển Latvia gần đây nhất có tỉ số là bao nhiêu?',\n",
        "    config={\"tools\": [{\"google_search\": {}}]},\n",
        ")\n",
        "\n",
        "# print the response\n",
        "display(Markdown(f\"**Response**:\\n {response.text}\"))\n",
        "# print the search details\n",
        "print(f\"Search Query: {response.candidates[0].grounding_metadata.web_search_queries}\")\n",
        "# urls used for grounding\n",
        "print(f\"Search Pages: {', '.join([site.web.title for site in response.candidates[0].grounding_metadata.grounding_chunks])}\")\n",
        "\n",
        "display(HTML(response.candidates[0].grounding_metadata.search_entry_point.rendered_content))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "id": "f47peR9YeyHu",
        "outputId": "d67eeacf-df92-450a-fff9-b21c2b335d10"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Response**:\n Trận đấu gần đây nhất giữa đội tuyển Anh và đội tuyển Latvia diễn ra vào ngày 14 tháng 10 năm 2025 (rạng sáng ngày 15 tháng 10 theo giờ Việt Nam) với tỉ số là Anh 5-0 Latvia. Trận đấu này thuộc khuôn khổ vòng loại World Cup 2026 khu vực châu Âu. Với chiến thắng này, đội tuyển Anh đã chính thức giành vé tham dự World Cup 2026."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Search Query: ['kết quả trận đấu đội tuyển Anh với đội tuyển Latvia gần đây nhất', 'England vs Latvia football match scores history']\n",
            "Search Pages: bongda.com.vn, laodong.vn, englandfootball.com, theguardian.com, nld.com.vn, vietnamnet.vn, vietnamplus.vn\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              ".container {\n",
              "  align-items: center;\n",
              "  border-radius: 8px;\n",
              "  display: flex;\n",
              "  font-family: Google Sans, Roboto, sans-serif;\n",
              "  font-size: 14px;\n",
              "  line-height: 20px;\n",
              "  padding: 8px 12px;\n",
              "}\n",
              ".chip {\n",
              "  display: inline-block;\n",
              "  border: solid 1px;\n",
              "  border-radius: 16px;\n",
              "  min-width: 14px;\n",
              "  padding: 5px 16px;\n",
              "  text-align: center;\n",
              "  user-select: none;\n",
              "  margin: 0 8px;\n",
              "  -webkit-tap-highlight-color: transparent;\n",
              "}\n",
              ".carousel {\n",
              "  overflow: auto;\n",
              "  scrollbar-width: none;\n",
              "  white-space: nowrap;\n",
              "  margin-right: -12px;\n",
              "}\n",
              ".headline {\n",
              "  display: flex;\n",
              "  margin-right: 4px;\n",
              "}\n",
              ".gradient-container {\n",
              "  position: relative;\n",
              "}\n",
              ".gradient {\n",
              "  position: absolute;\n",
              "  transform: translate(3px, -9px);\n",
              "  height: 36px;\n",
              "  width: 9px;\n",
              "}\n",
              "@media (prefers-color-scheme: light) {\n",
              "  .container {\n",
              "    background-color: #fafafa;\n",
              "    box-shadow: 0 0 0 1px #0000000f;\n",
              "  }\n",
              "  .headline-label {\n",
              "    color: #1f1f1f;\n",
              "  }\n",
              "  .chip {\n",
              "    background-color: #ffffff;\n",
              "    border-color: #d2d2d2;\n",
              "    color: #5e5e5e;\n",
              "    text-decoration: none;\n",
              "  }\n",
              "  .chip:hover {\n",
              "    background-color: #f2f2f2;\n",
              "  }\n",
              "  .chip:focus {\n",
              "    background-color: #f2f2f2;\n",
              "  }\n",
              "  .chip:active {\n",
              "    background-color: #d8d8d8;\n",
              "    border-color: #b6b6b6;\n",
              "  }\n",
              "  .logo-dark {\n",
              "    display: none;\n",
              "  }\n",
              "  .gradient {\n",
              "    background: linear-gradient(90deg, #fafafa 15%, #fafafa00 100%);\n",
              "  }\n",
              "}\n",
              "@media (prefers-color-scheme: dark) {\n",
              "  .container {\n",
              "    background-color: #1f1f1f;\n",
              "    box-shadow: 0 0 0 1px #ffffff26;\n",
              "  }\n",
              "  .headline-label {\n",
              "    color: #fff;\n",
              "  }\n",
              "  .chip {\n",
              "    background-color: #2c2c2c;\n",
              "    border-color: #3c4043;\n",
              "    color: #fff;\n",
              "    text-decoration: none;\n",
              "  }\n",
              "  .chip:hover {\n",
              "    background-color: #353536;\n",
              "  }\n",
              "  .chip:focus {\n",
              "    background-color: #353536;\n",
              "  }\n",
              "  .chip:active {\n",
              "    background-color: #464849;\n",
              "    border-color: #53575b;\n",
              "  }\n",
              "  .logo-light {\n",
              "    display: none;\n",
              "  }\n",
              "  .gradient {\n",
              "    background: linear-gradient(90deg, #1f1f1f 15%, #1f1f1f00 100%);\n",
              "  }\n",
              "}\n",
              "</style>\n",
              "<div class=\"container\">\n",
              "  <div class=\"headline\">\n",
              "    <svg class=\"logo-light\" width=\"18\" height=\"18\" viewBox=\"9 9 35 35\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\">\n",
              "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M42.8622 27.0064C42.8622 25.7839 42.7525 24.6084 42.5487 23.4799H26.3109V30.1568H35.5897C35.1821 32.3041 33.9596 34.1222 32.1258 35.3448V39.6864H37.7213C40.9814 36.677 42.8622 32.2571 42.8622 27.0064V27.0064Z\" fill=\"#4285F4\"/>\n",
              "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M26.3109 43.8555C30.9659 43.8555 34.8687 42.3195 37.7213 39.6863L32.1258 35.3447C30.5898 36.3792 28.6306 37.0061 26.3109 37.0061C21.8282 37.0061 18.0195 33.9811 16.6559 29.906H10.9194V34.3573C13.7563 39.9841 19.5712 43.8555 26.3109 43.8555V43.8555Z\" fill=\"#34A853\"/>\n",
              "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M16.6559 29.8904C16.3111 28.8559 16.1074 27.7588 16.1074 26.6146C16.1074 25.4704 16.3111 24.3733 16.6559 23.3388V18.8875H10.9194C9.74388 21.2072 9.06992 23.8247 9.06992 26.6146C9.06992 29.4045 9.74388 32.022 10.9194 34.3417L15.3864 30.8621L16.6559 29.8904V29.8904Z\" fill=\"#FBBC05\"/>\n",
              "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M26.3109 16.2386C28.85 16.2386 31.107 17.1164 32.9095 18.8091L37.8466 13.8719C34.853 11.082 30.9659 9.3736 26.3109 9.3736C19.5712 9.3736 13.7563 13.245 10.9194 18.8875L16.6559 23.3388C18.0195 19.2636 21.8282 16.2386 26.3109 16.2386V16.2386Z\" fill=\"#EA4335\"/>\n",
              "    </svg>\n",
              "    <svg class=\"logo-dark\" width=\"18\" height=\"18\" viewBox=\"0 0 48 48\" xmlns=\"http://www.w3.org/2000/svg\">\n",
              "      <circle cx=\"24\" cy=\"23\" fill=\"#FFF\" r=\"22\"/>\n",
              "      <path d=\"M33.76 34.26c2.75-2.56 4.49-6.37 4.49-11.26 0-.89-.08-1.84-.29-3H24.01v5.99h8.03c-.4 2.02-1.5 3.56-3.07 4.56v.75l3.91 2.97h.88z\" fill=\"#4285F4\"/>\n",
              "      <path d=\"M15.58 25.77A8.845 8.845 0 0 0 24 31.86c1.92 0 3.62-.46 4.97-1.31l4.79 3.71C31.14 36.7 27.65 38 24 38c-5.93 0-11.01-3.4-13.45-8.36l.17-1.01 4.06-2.85h.8z\" fill=\"#34A853\"/>\n",
              "      <path d=\"M15.59 20.21a8.864 8.864 0 0 0 0 5.58l-5.03 3.86c-.98-2-1.53-4.25-1.53-6.64 0-2.39.55-4.64 1.53-6.64l1-.22 3.81 2.98.22 1.08z\" fill=\"#FBBC05\"/>\n",
              "      <path d=\"M24 14.14c2.11 0 4.02.75 5.52 1.98l4.36-4.36C31.22 9.43 27.81 8 24 8c-5.93 0-11.01 3.4-13.45 8.36l5.03 3.85A8.86 8.86 0 0 1 24 14.14z\" fill=\"#EA4335\"/>\n",
              "    </svg>\n",
              "    <div class=\"gradient-container\"><div class=\"gradient\"></div></div>\n",
              "  </div>\n",
              "  <div class=\"carousel\">\n",
              "    <a class=\"chip\" href=\"https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQECHbk8bdt2iik63iuMqGN8Kx2-2setCdyuoLO4bRDYzoIBvcWOfaCGbT4nX-jCYUB2M0Wja-t6Osocjnxn990ErLM7y7pipIbJD8zGnec-anlgGVYOlN_zAeZsodauZnA9uChnwi0NQlK1C9an2UnrKCNDUs8H-q7YDOI4dXyo83600pY0WuyNwWWwzhGZucTTV7w-vxyhwEpK_3c1C_eLUp9geoE1UnZYPG1FA5yXKXjF8bN-FyF4P4iEEeAShxxDnMupmseiFy8cNLjYp-eYu0mmpYmZIBIs9_IEmViR_zuzjMupxIIQvti1jad9zaCrFkq0aavpeBasZMusWmIYh9ZHwbpCilacwegvLX4Gd27XIL7VlAUrzfpMJLPfZRfJ1AAklp2BchPxAYdtlKNdyy4yd5k=\">kết quả trận đấu đội tuyển Anh với đội tuyển Latvia gần đây nhất</a>\n",
              "    <a class=\"chip\" href=\"https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHkIdAqk8u0y8GK1XTrcEzRCyMBNWxPCa3evedXUy4YqQ6Kvlw1saNxBGxDamEQxhL70PZS1dl2ydT49S6kgXbZtIl6F2_akhnDgA4DQR5uzHQXYQ0ClyVIkUaNdYPlbCaCGYNmJNNMliaNOKJGTAP_RDStV5ERaQls2Y8vEIPdlL2ZHILEnfjmdk1Z-611yHWdi-6Kwq6iGbyclkj4MCpSRzkVSqPUX2jITpxGcTeUIaSf\">England vs Latvia football match scores history</a>\n",
              "  </div>\n",
              "</div>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Markdown\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents='Trận đấu cuối cùng của Harry Kane cho Tottenham diễn ra vào ngày bao nhiêu?',\n",
        ")\n",
        "\n",
        "# print the response\n",
        "display(Markdown(response.text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "4XJsfVaQe0Wf",
        "outputId": "be54cafc-5f61-4a90-ae78-10faf95437e0"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Trận đấu cuối cùng của Harry Kane cho Tottenham là vào ngày **28 tháng 5 năm 2023**.\n\nĐó là trận đấu cuối cùng của mùa giải Premier League 2022/2023, khi Tottenham đánh bại Leeds United với tỷ số 4-1. Kane đã ghi 2 bàn trong trận đấu đó. Anh chính thức chuyển đến Bayern Munich vào tháng 8 năm 2023."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Grounding with YouTube links"
      ],
      "metadata": {
        "id": "CYs7uIPEe2TH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "yt_link = \"https://www.youtube.com/watch?v=XV1kOFo1C8M\"\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents= types.Content(\n",
        "        parts=[\n",
        "            types.Part(text=\"Summarize this video.\"),\n",
        "            types.Part(\n",
        "                file_data=types.FileData(\n",
        "                    file_uri=yt_link\n",
        "                )\n",
        "            )\n",
        "        ]\n",
        "    )\n",
        ")\n",
        "\n",
        "Markdown(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "id": "lR41PDeRe24_",
        "outputId": "e4c19fda-e5d6-462f-93ec-e5b1ca9d8fd8"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "This video introduces \"Gemma Chess,\" an application of Google's Gemma AI model designed to bring a new dimension to the game of chess. The speaker, Ju-yeong Ji from Google DeepMind, clarifies that Gemma is not meant to replace traditional chess engines like AlphaZero, which are highly specialized for calculating the best moves. Instead, Gemma leverages its natural language processing capabilities to enhance the human experience of chess.\n\nKey applications of Gemma in chess include:\n\n1.  **Explaining Chess Analysis:** Gemma can interpret complex technical outputs from traditional chess engines (like PGN data and numerical evaluations) and translate them into understandable plain text explanations. It can detail the strategic and tactical reasons behind specific moves, identify major themes, and highlight potential dangers, making game analysis more accessible to players.\n2.  **Storytelling:** Gemma can narrate the progression of chess games, turning a sequence of moves into an engaging story by incorporating details about players, tournaments, and the unfolding drama of the match. This aims to bring games to life in a way that mere move notation cannot.\n3.  **Supporting Chess Learning:** Gemma can act as a personalized study partner, explaining chess concepts (such as openings like the Sicilian Defense or positional ideas like \"passed pawns\") in natural language, and even in different languages like Korean. It can provide tailored feedback based on a player's skill level, clarifying complex ideas and suggesting areas for improvement, akin to having a 24/7 personal chess coach.\n\nIn summary, Gemma enhances the chess experience by focusing on understanding, explaining, and narrating the game in a human-like manner, making learning easier, analysis more intuitive, and games more engaging for players of all levels."
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "yt_link = \"https://www.youtube.com/watch?v=XV1kOFo1C8M\"\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=types.Content(\n",
        "        parts=[\n",
        "            types.Part(text=\"In 2 paragraph, how Gemma models can help on chess games?\"),\n",
        "            types.Part(\n",
        "                file_data=types.FileData(file_uri=yt_link)\n",
        "            )\n",
        "        ]\n",
        "    )\n",
        ")\n",
        "\n",
        "Markdown(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "vYtgCvffe4ig",
        "outputId": "c18b33fb-c2a5-4565-b05e-ce40379e398b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Gemma models, as large language models, offer a distinct approach to chess compared to traditional engines like Stockfish or AlphaZero. While these engines excel at brute-force calculation and identifying optimal moves through deep search, Gemma's strength lies in its ability to understand, generate, and process human language. This capability allows Gemma to act as a sophisticated explainer and analyst for chess games. It can interpret complex game notations (like PGN) and provide human-understandable explanations for strategic decisions, tactical patterns, and positional nuances. Rather than just presenting a move and its numerical evaluation, Gemma can articulate *why* a move is interesting, the underlying plans, and potential dangers, effectively bridging the gap between raw computational data and human intuition. It can also be integrated with existing chess engines via function calls to query for optimal moves and then interpret those results.\n\nFurthermore, Gemma can significantly enhance chess learning and engagement. It can serve as a personalized chess tutor, explaining openings, tactical motifs, or strategic concepts (like a passed pawn) in plain language, tailored to a user's skill level and even in different languages. Beyond analysis, Gemma can transform game data into engaging narratives, recounting the drama and key moments of famous historical matches or even a user's own games, thereby bringing the game to life in a more relatable way. This narrative capability, combined with its multilingual understanding, makes chess more accessible and enjoyable for a broader audience, fostering deeper understanding and appreciation of the game's intricacies rather than merely focusing on competitive play."
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Grounding information using URL context"
      ],
      "metadata": {
        "id": "cwXO7eBue7uo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"\n",
        "  Based on https://ai.google.dev/gemini-api/docs/models, what are the key\n",
        "  differences between Gemini 1.5, Gemini 2.0 and Gemini 2.5 models?\n",
        "  Create a markdown table comparing the differences.\n",
        "\"\"\"\n",
        "\n",
        "config = {\n",
        "    \"tools\": [{\"url_context\": {}}],\n",
        "}\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    contents=[prompt],\n",
        "    model=MODEL_ID,\n",
        "    config=config\n",
        ")\n",
        "\n",
        "display(Markdown(response.text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 724
        },
        "id": "q10d9Vnie8MZ",
        "outputId": "bc5760d7-0c39-4640-efbf-7fe0091ef363"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "The provided document details Gemini 2.5 Pro, Gemini 2.5 Flash, Gemini 2.5 Flash-Lite, Gemini 2.0 Flash, and Gemini 2.0 Flash-Lite. There is no mention of a standalone \"Gemini 1.5\" or \"Gemini 2.0\" model, but rather different versions of 2.0 and 2.5. I will compare the \"Pro\" and \"Flash\" versions within 2.0 and 2.5, as these appear to be the primary distinctions within those generations, and the \"Flash-Lite\" models are essentially optimized versions of the \"Flash\" models.\n\nHere's a breakdown of the key differences based on the provided documentation:\n\n| Feature           | Gemini 2.5 Pro                                                                                                                                                                                                                                                                                                 | Gemini 2.5 Flash                                                                                                                                                                                                                                                                                                                                                                           | Gemini 2.0 Flash                                                                                                                                                                                                                                                                                                                                                                    |\n| :---------------- | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |\n| **Description**   | State-of-the-art thinking model, capable of reasoning over complex problems in code, math, and STEM, as well as analyzing large datasets, codebases, and documents using long context.                                                                                                                         | Our best model in terms of price-performance, offering well-rounded capabilities. Best for large scale processing, low-latency, high volume tasks that require thinking, and agentic use cases.                                                                                                                                                                                     | Second-generation workhorse model with a 1 million token context window. Delivers next-gen features and improved capabilities, including superior speed, native tool use, and a 1M token context window.                                                                                                                                                                        |\n| **Model Code**    | `gemini-2.5-pro`                                                                                                                                                                                                                                                                                                 | `gemini-2.5-flash`                                                                                                                                                                                                                                                                                                                                                                       | `gemini-2.0-flash`                                                                                                                                                                                                                                                                                                                                                                        |\n| **Input Token Limit** | 1,048,576                                                                                                                                                                                                                                                                                                      | 1,048,576                                                                                                                                                                                                                                                                                                                                                                                | 1,048,576                                                                                                                                                                                                                                                                                                                                                                 |\n| **Output Token Limit**| 65,536                                                                                                                                                                                                                                                                                                       | 65,536                                                                                                                                                                                                                                                                                                                                                                                 | 8,192                                                                                                                                                                                                                                                                                                                                                                        |\n| **Supported Data Types (Inputs)** | Audio, images, video, text, and PDF                                                                                                                                                                                                                                                              | Text, images, video, audio                                                                                                                                                                                                                                                                                                                                                             | Audio, images, video, and text                                                                                                                                                                                                                                                                                                                                                        |\n| **Supported Data Types (Outputs)** | Text                                                                                                                                                                                                                                                                                             | Text                                                                                                                                                                                                                                                                                                                                                                                     | Text                                                                                                                                                                                                                                                                                                                                                                                    |\n| **Thinking Capability** | Supported                                                                                                                                                                                                                                                                                                      | Supported                                                                                                                                                                                                                                                                                                                                                                                | Experimental                                                                                                                                                                                                                                                                                                                                                                        |\n| **URL Context**   | Supported                                                                                                                                                                                                                                                                                                      | Supported                                                                                                                                                                                                                                                                                                                                                                                | Not supported                                                                                                                                                                                                                                                                                                                                                                     |\n| **Latest Update** | June 2025                                                                                                                                                                                                                                                                                                        | June 2025                                                                                                                                                                                                                                                                                                                                                                                | February 2025                                                                                                                                                                                                                                                                                                                                                                       |\n| **Knowledge Cutoff** | January 2025                                                                                                                                                                                                                                                                                                     | January 2025                                                                                                                                                                                                                                                                                                                                                                             | August 2024                                                                                                                                                                                                                                                                                                                                                                         |\n| **Live API** | Not supported | Not supported (for base Gemini 2.5 Flash, but specific `gemini-2.5-flash-native-audio-preview` supports it)| Supported |"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get URLs retrieved for context\n",
        "print(response.candidates[0].url_context_metadata)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dOTNp-WZe9py",
        "outputId": "62406488-27ac-418d-ceb8-fb35615202af"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "url_metadata=[UrlMetadata(\n",
            "  retrieved_url='https://abc.xyz/assets/cc/27/3ada14014efbadd7a58472f1f3f4/2025q2-alphabet-earnings-release.pdf',\n",
            "  url_retrieval_status=<UrlRetrievalStatus.URL_RETRIEVAL_STATUS_SUCCESS: 'URL_RETRIEVAL_STATUS_SUCCESS'>\n",
            ")]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Add PDFs by URL"
      ],
      "metadata": {
        "id": "xwqvzlpJe_SR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"\n",
        "  Can you give me an overview of the content of this pdf?\n",
        "  https://abc.xyz/assets/cc/27/3ada14014efbadd7a58472f1f3f4/2025q2-alphabet-earnings-release.pdf\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "config = {\n",
        "    \"tools\": [{\"url_context\": {}}],\n",
        "}\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    contents=[prompt],\n",
        "    model=MODEL_ID,\n",
        "    config=config\n",
        ")\n",
        "\n",
        "display(Markdown(response.text.replace('$','$')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "rZ9z0aaQfA-Z",
        "outputId": "8e14fe13-3fac-4f72-c80a-6cf934e0ed72"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "\n\nThe provided PDF document is the \"2025 Q2 Alphabet Earnings Release\". However, the `browse` tool was not able to extract the actual content of the earnings release. Instead, it returned the site map for Alphabet Investor Relations. This suggests that the PDF content is not directly parsable by the tool in a way that would provide the financial details. Therefore, I cannot provide an overview of the earnings release itself.\n\nThe document at the provided URL is a 2025 Q2 Alphabet Earnings Release, but the browsing tool could only extract the site map for Alphabet Investor Relations, not the actual financial content. I am unable to provide an overview of the PDF's content based on the information extracted.\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Add images by URL"
      ],
      "metadata": {
        "id": "XnKdgS9zfDbC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"\n",
        "  Can you help me name of the numbered parts of that instrument, in French?\n",
        "  https://upload.wikimedia.org/wikipedia/commons/thumb/4/40/Trombone.svg/960px-Trombone.svg.png\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "config = {\n",
        "    \"tools\": [{\"url_context\": {}}],\n",
        "}\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    contents=[prompt],\n",
        "    model=MODEL_ID,\n",
        "    config=config\n",
        ")\n",
        "\n",
        "display(Markdown(response.text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "id": "MaB_1CTofD_r",
        "outputId": "bf1daa61-f606-4bd8-b910-d7efd66c0883"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Here are the names of the numbered parts of the trombone in French, based on the provided image:\n\n1.  **Clé d'eau** (Water Key / Spit Valve)\n2.  **Embouchure** (Mouthpiece)\n3.  **Pavillon** (Bell)\n4.  **Coulisse d'accord** (Tuning Slide)\n5.  **Coulisse extérieure** (Outer Slide)\n6.  **Entretoise de pavillon** (Bell Brace / Stay)\n7.  **Coulisse intérieure** (Inner Slide)\n8.  **Verrou de coulisse** (Slide Lock / Collar)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mix Search grounding and URL context"
      ],
      "metadata": {
        "id": "lKuFItmcfFdr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"\n",
        "  Can you give me an overview of the content of this pdf?\n",
        "  https://abc.xyz/assets/cc/27/3ada14014efbadd7a58472f1f3f4/2025q2-alphabet-earnings-release.pdf\n",
        "  Search on the web for the reaction of the main financial analysts, what's the trend?\n",
        "\"\"\"\n",
        "\n",
        "config = {\n",
        "  \"tools\": [\n",
        "      {\"url_context\": {}},\n",
        "      {\"google_search\": {}}\n",
        "  ],\n",
        "}\n",
        "\n",
        "response = client.models.generate_content(\n",
        "  contents=[prompt],\n",
        "  model=MODEL_ID,\n",
        "  config=config\n",
        ")\n",
        "\n",
        "display(Markdown(response.text.replace('$','$')))\n",
        "display(HTML(response.candidates[0].grounding_metadata.search_entry_point.rendered_content))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 464
        },
        "id": "NO5DTB4IfGwL",
        "outputId": "83e4c226-fb69-4a8c-df81-55e47c1a7185"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "I am unable to provide an overview of the content of the PDF directly as the browsing tool could not extract its content. It appears to have returned the surrounding webpage information rather than the PDF's text itself.\n\nHowever, I can proceed with searching for financial analysts' reactions to Alphabet's 2025 Q2 earnings release.The browsing tool was unable to provide an overview of the PDF content directly.\n\nRegarding financial analysts' reactions to Alphabet's 2025 Q2 earnings release, the trend is largely bullish, with most analysts issuing \"buy\" or equivalent ratings. Alphabet reported strong financial performance, exceeding analyst expectations for revenue and earnings per share (EPS).\n\nKey takeaways from the analysts' reactions include:\n*   **Strong Financial Performance**: Alphabet's Q2 2025 revenue was $96.4 billion, a 14% year-over-year increase, beating the expected $94.0 billion. Net income rose 19% to $28.2 billion, with EPS at $2.33, surpassing estimates.\n*   **AI Investments and Returns**: Alphabet is making massive investments in AI, increasing its capital expenditures forecast to $85 billion for 2025. These investments are beginning to show tangible returns, with AI Overviews now having over 2 billion monthly users. Analysts believe Google's Cloud division benefits from strong enterprise demand and AI momentum.\n*   **Google Cloud Growth**: Google Cloud revenue was a significant highlight, reaching $13.6 billion (up 32% year-over-year), exceeding expectations.\n*   **Advertising Revenue Focus**: Advertising revenue remains a focus, with Google's Search and Other division revenue projected to have risen about 9% to $52.93 billion. However, the rise of generative AI poses a potential threat to traditional search.\n*   **Market Reactions**: Initially, the stock saw a slight dip due to concerns over soaring capital expenditures, but quickly rebounded as analysts and institutional investors processed the long-term vision.\n*   **Antitrust Concerns**: Wall Street is also monitoring an antitrust case ruling expected in the near future that could potentially impact Google's Chrome browser."
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              ".container {\n",
              "  align-items: center;\n",
              "  border-radius: 8px;\n",
              "  display: flex;\n",
              "  font-family: Google Sans, Roboto, sans-serif;\n",
              "  font-size: 14px;\n",
              "  line-height: 20px;\n",
              "  padding: 8px 12px;\n",
              "}\n",
              ".chip {\n",
              "  display: inline-block;\n",
              "  border: solid 1px;\n",
              "  border-radius: 16px;\n",
              "  min-width: 14px;\n",
              "  padding: 5px 16px;\n",
              "  text-align: center;\n",
              "  user-select: none;\n",
              "  margin: 0 8px;\n",
              "  -webkit-tap-highlight-color: transparent;\n",
              "}\n",
              ".carousel {\n",
              "  overflow: auto;\n",
              "  scrollbar-width: none;\n",
              "  white-space: nowrap;\n",
              "  margin-right: -12px;\n",
              "}\n",
              ".headline {\n",
              "  display: flex;\n",
              "  margin-right: 4px;\n",
              "}\n",
              ".gradient-container {\n",
              "  position: relative;\n",
              "}\n",
              ".gradient {\n",
              "  position: absolute;\n",
              "  transform: translate(3px, -9px);\n",
              "  height: 36px;\n",
              "  width: 9px;\n",
              "}\n",
              "@media (prefers-color-scheme: light) {\n",
              "  .container {\n",
              "    background-color: #fafafa;\n",
              "    box-shadow: 0 0 0 1px #0000000f;\n",
              "  }\n",
              "  .headline-label {\n",
              "    color: #1f1f1f;\n",
              "  }\n",
              "  .chip {\n",
              "    background-color: #ffffff;\n",
              "    border-color: #d2d2d2;\n",
              "    color: #5e5e5e;\n",
              "    text-decoration: none;\n",
              "  }\n",
              "  .chip:hover {\n",
              "    background-color: #f2f2f2;\n",
              "  }\n",
              "  .chip:focus {\n",
              "    background-color: #f2f2f2;\n",
              "  }\n",
              "  .chip:active {\n",
              "    background-color: #d8d8d8;\n",
              "    border-color: #b6b6b6;\n",
              "  }\n",
              "  .logo-dark {\n",
              "    display: none;\n",
              "  }\n",
              "  .gradient {\n",
              "    background: linear-gradient(90deg, #fafafa 15%, #fafafa00 100%);\n",
              "  }\n",
              "}\n",
              "@media (prefers-color-scheme: dark) {\n",
              "  .container {\n",
              "    background-color: #1f1f1f;\n",
              "    box-shadow: 0 0 0 1px #ffffff26;\n",
              "  }\n",
              "  .headline-label {\n",
              "    color: #fff;\n",
              "  }\n",
              "  .chip {\n",
              "    background-color: #2c2c2c;\n",
              "    border-color: #3c4043;\n",
              "    color: #fff;\n",
              "    text-decoration: none;\n",
              "  }\n",
              "  .chip:hover {\n",
              "    background-color: #353536;\n",
              "  }\n",
              "  .chip:focus {\n",
              "    background-color: #353536;\n",
              "  }\n",
              "  .chip:active {\n",
              "    background-color: #464849;\n",
              "    border-color: #53575b;\n",
              "  }\n",
              "  .logo-light {\n",
              "    display: none;\n",
              "  }\n",
              "  .gradient {\n",
              "    background: linear-gradient(90deg, #1f1f1f 15%, #1f1f1f00 100%);\n",
              "  }\n",
              "}\n",
              "</style>\n",
              "<div class=\"container\">\n",
              "  <div class=\"headline\">\n",
              "    <svg class=\"logo-light\" width=\"18\" height=\"18\" viewBox=\"9 9 35 35\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\">\n",
              "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M42.8622 27.0064C42.8622 25.7839 42.7525 24.6084 42.5487 23.4799H26.3109V30.1568H35.5897C35.1821 32.3041 33.9596 34.1222 32.1258 35.3448V39.6864H37.7213C40.9814 36.677 42.8622 32.2571 42.8622 27.0064V27.0064Z\" fill=\"#4285F4\"/>\n",
              "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M26.3109 43.8555C30.9659 43.8555 34.8687 42.3195 37.7213 39.6863L32.1258 35.3447C30.5898 36.3792 28.6306 37.0061 26.3109 37.0061C21.8282 37.0061 18.0195 33.9811 16.6559 29.906H10.9194V34.3573C13.7563 39.9841 19.5712 43.8555 26.3109 43.8555V43.8555Z\" fill=\"#34A853\"/>\n",
              "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M16.6559 29.8904C16.3111 28.8559 16.1074 27.7588 16.1074 26.6146C16.1074 25.4704 16.3111 24.3733 16.6559 23.3388V18.8875H10.9194C9.74388 21.2072 9.06992 23.8247 9.06992 26.6146C9.06992 29.4045 9.74388 32.022 10.9194 34.3417L15.3864 30.8621L16.6559 29.8904V29.8904Z\" fill=\"#FBBC05\"/>\n",
              "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M26.3109 16.2386C28.85 16.2386 31.107 17.1164 32.9095 18.8091L37.8466 13.8719C34.853 11.082 30.9659 9.3736 26.3109 9.3736C19.5712 9.3736 13.7563 13.245 10.9194 18.8875L16.6559 23.3388C18.0195 19.2636 21.8282 16.2386 26.3109 16.2386V16.2386Z\" fill=\"#EA4335\"/>\n",
              "    </svg>\n",
              "    <svg class=\"logo-dark\" width=\"18\" height=\"18\" viewBox=\"0 0 48 48\" xmlns=\"http://www.w3.org/2000/svg\">\n",
              "      <circle cx=\"24\" cy=\"23\" fill=\"#FFF\" r=\"22\"/>\n",
              "      <path d=\"M33.76 34.26c2.75-2.56 4.49-6.37 4.49-11.26 0-.89-.08-1.84-.29-3H24.01v5.99h8.03c-.4 2.02-1.5 3.56-3.07 4.56v.75l3.91 2.97h.88z\" fill=\"#4285F4\"/>\n",
              "      <path d=\"M15.58 25.77A8.845 8.845 0 0 0 24 31.86c1.92 0 3.62-.46 4.97-1.31l4.79 3.71C31.14 36.7 27.65 38 24 38c-5.93 0-11.01-3.4-13.45-8.36l.17-1.01 4.06-2.85h.8z\" fill=\"#34A853\"/>\n",
              "      <path d=\"M15.59 20.21a8.864 8.864 0 0 0 0 5.58l-5.03 3.86c-.98-2-1.53-4.25-1.53-6.64 0-2.39.55-4.64 1.53-6.64l1-.22 3.81 2.98.22 1.08z\" fill=\"#FBBC05\"/>\n",
              "      <path d=\"M24 14.14c2.11 0 4.02.75 5.52 1.98l4.36-4.36C31.22 9.43 27.81 8 24 8c-5.93 0-11.01 3.4-13.45 8.36l5.03 3.85A8.86 8.86 0 0 1 24 14.14z\" fill=\"#EA4335\"/>\n",
              "    </svg>\n",
              "    <div class=\"gradient-container\"><div class=\"gradient\"></div></div>\n",
              "  </div>\n",
              "  <div class=\"carousel\">\n",
              "    <a class=\"chip\" href=\"https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGYFR6eBPNHXfaBUq_R467HJWE0mTpkv3nJT47hDS70Mk3zMowTYTMHXyCpMI_IwaWzER0Dgi9N0vBUGdWsLrd9rGt8tnoieRD2Oe1A_m7D3C3nhXmxmc86yTaWwrkrQbg8gAKXz6b6idPjRDziJbTKpuc0-iNhbhf9cynJYM4QwEl8hhmjeQckCTdHIh-GUB3Jp1ZsUU5cQwW6SzJB7hKgF5IVjZUZ5qCJDC3w9RNfiV_YLo1-lZIO-Ry_NC2IIP8t\">financial analysts reaction Alphabet 2025 Q2 earnings release</a>\n",
              "  </div>\n",
              "</div>\n"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "Tce3stUlHN0L"
      ],
      "name": "Grounding.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}